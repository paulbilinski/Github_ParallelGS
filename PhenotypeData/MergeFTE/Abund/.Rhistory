install.packages("raster")
library(raster);
install.packages("dismo")
install.packages("dismo")
install.packages("dismo")
install.packages("driftsel")
library(driftsel)
cor.test(comb$V1.x, comb$V1.y)
bwa <- read.csv("bwamem_estimates.csv", header=FALSE)
mosaik <- read.csv("mosaikrimma0385.csv",header=FALSE)
comb <- merge(mosaik, bwa, by="V2", all=TRUE)
?merge
cor.test(comb$V1.x, comb$V1.y)
cor(comb$V1.x, comb$V1.y)
cor(comb$V1.x, comb$V1.y, na.rm=TRUE)
?cor
cor(comb$V1.x, comb$V1.y, use="pairwise.complete.obs")
fit = lm(comb$V1.x ~ comb$V1.y)
summary(fit)$r.squared
distances <- c(6209604,1355654,10708,1398843,10659,8523,85021,4685,8593,10184,69276,29808,5571,5423,7838,12180,2502636,1863,7161,15167,2198,3180,12130,4461,34737,9714,8423,1793,10025,5742,3588,14802,4992,25081,22143,5565,29686,9496,18803,7707,4586,23386178,3942,8666,18312,9232,43544,25054,1250,15628,5006,5952427,93418331,42706,19258,2148803,67200,7112,2035,11317,5921,2058,15974,1450,10544,18988,1224,14221728,14257784,9476798,14225472,54416488,9727128,17461,5724,8535,2173,19691,1050,3297,15789,83142020,16407762,38053,3628126,4148409,3011,7174,24562,4597,9571,5091,41561,9056,10042,1365,16021,2228,15334,13111,7970,3253,1307,970606,2090,4572,1097,16446,1422,13895,9233,1247,2070,11418,9288,5185,2045,4509,2602,1792,6506,14062,1908,4987,11531,5437,3961,7950,3530,1430,4158,7806,52940,1430,1509,3072,3721,2853,19497426,12058013,1495,7097,5545,7339,4658,7766,8769,7848,2418622,3101335,1346,12247,7098,9640,4509,7239,106415,484025,1181926,4083,1848,3707,1961,9063,1741,1201,7052,5934,4016,2163,4518,4329,7046,1472,3226,4283,20624242,30694655,7367,27045536,1566203,15473134,1689,6828,2704,4195,12767,20564,29121,2414,15532,9909,6613,7136,23087,26624,2713,2717,1597,84715,11548,21309248,7715783,2911,12157,8437,17999,59172,24331,2585,22597,20353,6130,7323,1793,7150,39074735,3210,14374,8636053,34106,19004,4529,382064,1028,25119,2269,266134,19498,2576344,7042,2530,15584,11103,34074,3560,146208,96416353)
hist(distances)
hist(distances, breaks=100)
hist(distances, breaks=100, xlim=c(0,100000))
hist(distances, breaks=100, xlim=c(0,1000000))
hist(distances, breaks=1000, xlim=c(0,1000000))
hist(distances, breaks=1000, xlim=c(0,100000))
hist(distances, breaks=10000, xlim=c(0,100000))
hist(distances, breaks=100000, xlim=c(0,100000))
hist(distances, breaks=100000, xlim=c(0,10000))
hist(distances, breaks=1000000, xlim=c(0,10000))
hist(distances, breaks=1000000, xlim=c(0,20000))
hist(distances, breaks=100000, xlim=c(0,15000))
density(distances)
plot(density(distances))
notfar <- subset(distances, distances<50000)
hist(notfar)
hist(notfar,breaks=100)
hist(notfar,breaks=50)
distances <- c(6209604,1355654,10708,1398843,10659,8523,85021,4685,8593,10184,69276,29808,5571,5423,7838,12180,2502636,1863,7161,15167,2198,3180,12130,4461,34737,9714,8423,1793,10025,5742,3588,14802,4992,25081,22143,5565,29686,9496,18803,7707,4586,23386178,3942,8666,18312,NA,9232,43544,25054,1250,15628,5006,5952427,93418331,NA,42706,19258,2148803,67200,7112,2035,11317,5921,2058,15974,1450,10544,18988,1224,14221728,14257784,9476798,NA,14225472,54416488,9727128,17461,5724,8535,2173,19691,1050,3297,15789,83142020,NA,16407762,38053,3628126,4148409,3011,7174,24562,4597,9571,5091,41561,9056,10042,1365,16021,2228,15334,13111,7970,3253,NA,1307,NA,970606,2090,4572,1097,16446,1422,13895,9233,1247,2070,11418,9288,5185,2045,4509,2602,1792,6506,14062,1908,4987,11531,5437,3961,7950,3530,1430,4158,7806,52940,1430,1509,3072,3721,2853,19497426,12058013,1495,7097,5545,7339,4658,7766,8769,7848,2418622,3101335,1346,12247,7098,9640,4509,7239,106415,484025,1181926,4083,1848,3707,NA,1961,9063,1741,1201,7052,5934,4016,2163,4518,4329,7046,1472,3226,4283,20624242,30694655,NA,7367,27045536,1566203,15473134,1689,6828,2704,4195,12767,20564,29121,2414,15532,9909,6613,7136,23087,26624,2713,2717,1597,84715,11548,21309248,7715783,NA,2911,12157,8437,17999,59172,24331,2585,22597,20353,6130,7323,1793,7150,39074735,3210,14374,8636053,34106,19004,4529,382064,1028,25119,2269,266134,19498,2576344,7042,2530,15584,11103,34074,3560,146208,96416353,NA)
notfar <- subset(distances, distances<50000)
plot(density(distances))
plot(density(distances, na.rm=TRUE))
hist(notfar,breaks=50, na.rm=TRUE)
hist(distances, breaks=100000, xlim=c(0,15000))
notfar <- subset(distances, distances<50000)
hist(notfar,breaks=50, na.rm=TRUE)
hor <- (1,2,3,4)
vert <- (.2, .6, .2, 0)
vert <- c(.2, .6, .2, 0)
hor <- c(1,2,3,4)
barplot(hor~vert)
plot(hor~vert)
plot(vert~hor)
barplot(vert~hor)
all<-c(1,3,2,2,2,2,2,2,1,3)
hist(all)
?barplot
barplot(vert)
?barplot
barplot(vert)
?barplot
vert <- c(.4, .6)
barplot(vert)
data <-(1359610, 183312, 1292667525, 705653049)
data <- c(1359610, 183312, 1292667525, 705653049)
mat1 <- matrix(data, 2)
View(mat1)
fisher.test(mat1)
teams <- c("pb","pk")
sample(teams)
?sample
teams <- c("pb","pk","bm","ra","mg","jl","jg","dm","kc","ad")
sample(teams)
sample(teams)
sample(teams)
sample(teams)
sample(teams)
sample(teams)
sample(teams)
sample(teams)
sample(teams)
sample(teams)
install.packages("~/Downloads/RAFM_1.1.tar.gz", repos = NULL, type = "source")
library(RAFM)
library(RAFM)
library(driftsel)
library(driftsel)
library(RAFM)
data(specimen)
head(specimen)
write.table(specimen, row.names=FALSE, file="specimen.txt")
write.table(specimen, row.names=TRUE, file="specimen.txt")
write.table(specimen, row.names=TRUE, file="specimen.txt") #this doesnt work
data(specimen)
head(specimen)
write.table(specimen, row.names=TRUE, file="specimen.txt") #this doesnt work
data(sticklebacks)
View(sticklebacks)
data(specimen)
data(shrew)
data(shrews)
View(shrews)
samp <- do.all(specimen, 100, 50, 2)
library(RAFM)
library(driftsel)
samp <- do.all(specimen, 100, 50, 2)
samp <- do.all(specimen, 100, 50, 2)
library(RAFM)
library(driftsel)
samp <- do.all(specimen, 100, 50, 2)
n=100
k=75
theta=0.5
dbinim(x=k,size=n,prob=theta)
dbinom(x=k,size=n,prob=theta)
dunif(theta,min=0,max=1)
dbeta(theta,shape1=10,shape2=10)
curve(dbeta(x=x,10,10),from=0,to=1,n=1001)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001)
curve(dbeta(x=x,1,1),from=0,to=1,n=1001)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001)
dbeta(theta,shape1=10,shape2=10)
uniformProposal = function(theta.current,tuning.parameter) {
theta.prime = runif(n=1,min=theta.current-tuning.parameter/2,max=theta.current+tuning.parameter/2)
if(theta.prime > 1) {
theta.prime = 2-theta.prime
}
if(theta.prime < 0) {
theta.prime = abs(theta.prime)
}
return(theta.prime)
}
uniformProposal = function(theta.current,tuning.parameter=0.1) {
theta.prime = runif(n=1,min=theta.current-tuning.parameter/2,max=theta.current+tuning.parameter/2)
if(theta.prime > 1) {
theta.prime = 2-theta.prime
}
if(theta.prime < 0) {
theta.prime = abs(theta.prime)
}
return(theta.prime)
}
uniformProposal(theta.current = 0.6)
uniformProposal(theta.current = 0.6)
uniformProposal(theta.current = 0.6)
uniformProposal(theta.current = 0.6)
uniformProposal(theta.current = 0.6)
uniformProposal(theta.current = 0.6)
ngen=1e6
sample.freq=100
theta.samples = numeric(ngen/sample.freq)
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
#write the MCMC
ngen=1e6
sample.freq=100
theta.samples = numeric(ngen/sample.freq)
accepted.moves = 0
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
p = dbeta(theta,5,5) #prior
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
theta.samples[i/sample.freq] = theta
}
}
theta.samples = numeric(ngen/sample.freq)
accepted.moves = 0
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
p = dbeta(theta,5,5) #prior
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
theta.samples[i/sample.freq] = theta
}
}
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
theta.samples[i/sample.freq] = theta
}
}
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
cat('*')
theta.samples[i/sample.freq] = theta
}
}
mean(theta.samples)
#write the MCMC
ngen=1e6
sample.freq=750
theta.samples = numeric(ngen/sample.freq)
accepted.moves = 0
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
p = dbeta(theta,5,5) #prior
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
cat('*')
theta.samples[i/sample.freq] = theta
}
}
mean(theta.samples)
hist(theta.samples,xlim=c(0,1),freq=FALSE)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001,add=TRUE)
accepted.moves/ngen
plot(theta.samples,ylim=c(0,1),type='1')
plot(theta.samples,ylim=c(0,1),type='l')
install.packages('coda')
library(coda)
geweke.diag(theta.samples)
ngen=1e6
sample.freq=100
theta.samples = numeric(ngen/sample.freq)
accepted.moves = 0
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
p = dbeta(theta,5,5) #prior
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
cat('*')
theta.samples[i/sample.freq] = theta
}
}
mean(theta.samples)
hist(theta.samples,xlim=c(0,1),freq=FALSE)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001,add=TRUE)
#acceptance rate
accepted.moves/ngen #little high, moving slowly, can just move uniformProposal to be bigger
plot(theta.samples,ylim=c(0,1),type='l')
install.packages('coda')
install.packages("coda")
library(coda)
geweke.diag(theta.samples)
geweke.diag(theta.samples)
ngen=1e6
sample.freq=100
theta.samples = numeric(ngen/sample.freq)
accepted.moves = 0
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
p = dbeta(theta,5,5) #prior
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
cat('*')
theta.samples[i/sample.freq] = theta
}
}
geweke.diag(theta.samples)
mean(theta.samples)
hist(theta.samples,xlim=c(0,1),freq=FALSE)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001,add=TRUE)
accepted.moves/ngen #little high, moving slowly, can just move uniformProposal to be bigger
plot(theta.samples,ylim=c(0,1),type='l')
geweke.diag(theta.samples)
effectiveSize(theta.samples)
ngen=1e3
sample.freq=1
theta.samples = numeric(ngen/sample.freq)
accepted.moves = 0
theta = rbeta(1,5,5)
l = dbinom(k,n,theta) #likelihood
p = dbeta(theta,5,5) #prior
for(i in 1:ngen) {
theta.prime = uniformProposal(theta) #propose a change to theta
l.prime = dbinom(k,n,theta.prime)
p.prime = dbeta(theta.prime,5,5)
a = (l.prime/l) *(p.prime/p)
if(runif(1,0,1) < a) {
theta= theta.prime
l=l.prime
p=p.prime
accepted.moves = accepted.moves+1
}
if (i %% sample.freq==0) {
cat('*')
theta.samples[i/sample.freq] = theta
}
}
mean(theta.samples)
hist(theta.samples,xlim=c(0,1),freq=FALSE)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001,add=TRUE)
#acceptance rate
accepted.moves/ngen #little high, moving slowly, can just move uniformProposal to be bigger
plot(theta.samples,ylim=c(0,1),type='l')
#install.packages('coda')
library(coda)
geweke.diag(theta.samples)
effectiveSize(theta.samples)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001,add=TRUE)
hist(theta.samples,xlim=c(0,1),freq=FALSE)
curve(dbeta(x=x,5,5),from=0,to=1,n=1001,add=TRUE)
plot(theta.samples,ylim=c(0,1),type='l')
5E-5
5E-5 > 6E-5
5E-5 < 6E-5
fit <- aov()
?aov()
library ( mvtnorm )
source('~/.active-rstudio-document', echo=TRUE)
library ( mvtnorm )
EnvVarTest <- function ( phenos , kinship.mat , test.vector ) {
# 'phenos' is a vector containing the phenotype
# (i.e. number of repeats) for each individual; dimensions are N x 1
# 'kinship.mat' is the kinship matrix; dimensions are N x N;
# rows and columns need to be in the same order as the phenotypes in the vector
# test.vector is the environmental factor of interest (in this case altitude)
eigs <- eigen ( kinship.mat )
# get eigendecomposition of kinship matrix
rt.inv <- eigs$vec %*% diag ( sqrt(eigs$val) )
# calculate inverse of the square root matrix
rotated.phenos <- t ( rt.inv ) %*% phenos
# rotate phenotypes from population space into principal component space
test.vector <- test.vector / (sqrt ( 2 * sum ( test.vector^2 ) ) )
# scale to be unit length after rotation
#recover()
rotated.vector <- rt.inv %*% test.vector
# rotate environmental variable from population space into principal component space
model <- lm ( rotated.phenos ~ 1+rotated.vector)
# fit regression model
r.sq <- cor.test ( rotated.phenos , rotated.vector )$estimate^2
# get r^2
ANOVA <- anova ( model )
# get p value
print(ANOVA)
return ( c ( model$coef[2] , r.sq , ANOVA[5][[1]][1] )) # return
}
phenoteo <-read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/Teosinte_averages.csv",header=TRUE)
View(phenoteo)
genoteo <- read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/SNP_data/TeosinteAll_Bayenv.csv",header=FALSE)
EnvVarTest(phenoteo$X180knobMB,genoteo,phenoteo$Altitude)
genoteo <- read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/SNP_data/TeosinteAll_Bayenv.csv",header=FALSE)
EnvVarTest(phenoteo$X180knobMB,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$X180knob.,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$X180knobMB,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$X180knob.,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$TR1MB,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$TR1.,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$CentCMB,genoteo,phenoteo$Altitude)
EnvVarTest(phenoteo$CentC.,genoteo,phenoteo$Altitude)
```
phenoparv <-read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/Teosinte_parv_avg.csv",header=TRUE)
genoparv <- read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/SNP_data/TeosinteParv_Bayenv.csv",header=FALSE)
EnvVarTest(phenoparv$X180knobMB,genoparv,phenoparv$Altitude)
EnvVarTest(phenoparv$X180knob.,genoparv,phenoparv$Altitude)
EnvVarTest(phenoparv$TR1MB,genoparv,phenoparv$Altitude)
EnvVarTest(phenoparv$TR1.,genoparv,phenoparv$Altitude)
EnvVarTest(phenoparv$CentCMB,genoparv,phenoparv$Altitude)
EnvVarTest(phenoparv$CentC.,genoparv,phenoparv$Altitude)
View(genoteo)
phenomex <-read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/Teosinte_mex_avg.csv",header=TRUE)
genomex <- read.csv("~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/SNP_data/TeosinteMex_Bayenv.csv",header=FALSE)
EnvVarTest(phenomex$X180knobMB,genomex,phenomex$Altitude)
EnvVarTest(phenomex$X180knob.,genomex,phenomex$Altitude)
EnvVarTest(phenomex$TR1MB,genomex,phenomex$Altitude)
EnvVarTest(phenomex$TR1.,genomex,phenomex$Altitude)
EnvVarTest(phenomex$CentCMB,genomex,phenomex$Altitude)
EnvVarTest(phenomex$CentC.,genomex,phenomex$Altitude)
tmp <- read.csv(file="FTE_id.fasta",header=FALSE)
setwd(dir = "~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE")
tmp <- read.csv(file="FTE_id.fasta",header=FALSE)
tmp1 <- read.csv(file="RIMME0033.1.fastq.abund",header=FALSE)
tmp1 <- read.csv(file="RIMPA0142.7.fastq.abund.head",header=FALSE)
setwd(dir = "~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/")
tmp <- read.csv(file="FTE_id.fasta",header=FALSE)
tmp2 <- read.csv(file="RIMPA0142.8.fastq.abund.head",header=FALSE)
crap <- merge(tmp,tmp1, all=TRUE,by="FTE",sort=TRUE)
tmp1 <- read.csv(file="RIMPA0142.7.fastq.abund.head",header=FALSE)
crap <- merge(tmp,tmp1, all=TRUE,by="FTE",sort=TRUE)
View(tmp1)
tmp1 <- read.csv(file="RIMPA0142.7.fastq.abund.head",header=TRUE)
tmp2 <- read.csv(file="RIMPA0142.8.fastq.abund.head",header=TRUE)
crap <- merge(tmp,tmp1, all=TRUE, by="FTE",sort=TRUE)
View(tmp1)
View(tmp2)
View(tmp)
tmp <- read.csv(file="FTE_id.fasta",header=TRUE)
tmp1 <- read.csv(file="RIMPA0142.7.fastq.abund.head",header=TRUE)
tmp2 <- read.csv(file="RIMPA0142.8.fastq.abund.head",header=TRUE)
crap <- merge(tmp,tmp1, all=TRUE, by="FTE",sort=TRUE)
crap <- merge(crap,tmp2,all=TRUE,by="V1",sort=TRUE)
View(tmp2)
View(crap)
crap <- merge(crap,tmp2,all=TRUE,by="FTE",sort=TRUE)
View(crap)
filenames=list.files(path=mypath, full.names=TRUE)
filenames=list.files(path="~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/", full.names=TRUE)
filenames=list.files(path="~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/", full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=TRUE)})
Reduce(function(x,y) {merge(x,y,all=TRUE,by="FTE")}, datalist)
umm <- Reduce(function(x,y) {merge(x,y,all=TRUE,by="FTE")}, datalist)
View(umm)
multmerge = function(mypath){
filenames=list.files(path=mypath, full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, datalist)
}
mutlmerge(~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/)
}
multmerge(/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/)
multmerge("/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/")
filenames=list.files(path="~/Documents/Projects/Genome_Size_Analysis/Github_ParallelGS/PhenotypeData/MergeFTE/Abund/", full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=TRUE)})
umm <- Reduce(function(x,y) {merge(x,y,all=TRUE,by="FTE")}, datalist)
View(umm)
FTE_merged <- Reduce(function(x,y) {merge(x,y,all=TRUE,by="FTE")}, datalist)
write.csv(FTE_merged, "289_FTE_merged.csv")
read.csv("289_FTE_sepID_merged.csv",header=TRUE)
sumem <- read.csv("289_FTE_sepID_merged.csv",header=TRUE)
View(sumem)
aggfte <- aggregate(sumem, by=FTE_group)
aggfte <- aggregate(sumem, by=FTE_group,FUN=sum)
aggfte <- aggregate(sumem, by=list(FTE_group),FUN=sum)
aggfte <- aggregate(sumem, by="FTE_group"", FUN=sum)
aggfte <- aggregate(sumem, by="FTE_group", FUN=sum)
aggfte <- aggregate(sumem, FTE_group, FUN=sum)
attach(mtcars)
aggdata <-aggregate(mtcars, by=list(cyl,vs),
FUN=mean, na.rm=TRUE)
View(aggdata)
aggfte <- aggregate(sumem, by=(FTE_group), FUN=sum)
aggfte <- aggregate(sumem, by=list(FTE_group,FTE_ID), FUN=sum)
aggfte <- aggregate(x=sumem, by=list(FTE_group,FTE_ID), FUN=sum)
View(sumem)
sumem <- read.csv("289_FTE_sepID_merged.csv",header=TRUE)
aggfte <- aggregate(x=sumem, by=list(crap,FTE_ID), FUN=sum)
sumem <- read.csv("289_FTE_sepID_merged.csv",header=TRUE)
aggfte <- aggregate(x=sumem, by=list(FTE_group,FTE_ID), FUN=sum)
aggfte <- aggregate(sumen$FTE_group, FUN=sum)
aggfte <- aggregate(sumem$FTE_group, FUN=sum)
aggfte <- aggregate(RIL0001.1.fastq.abund~FTE_group, sumem, sum)
View(aggfte)
row.names(sumem)
column.names(sumem)
col.names(sumem)
colnames(sumem)
aggfte <- aggregate(colnames(sumem)~FTE_group, sumem, sum)
aggfte <- aggregate(FTE_group~RIMMA0382.1.fastq.abund, sumem, sum)
aggfte <- aggregate(RIMMA0382.1.fastq.abund~FTE_group, sumem, sum)
View(aggfte)
aggfte <- aggregate(RIMMA0382.1.fastq.abund+RIMMA0383.1.fastq.abund~FTE_group, sumem, sum)
View(aggfte)
